---
title: "Search Diary"
date: 2022-02-07
tags:
- fruit
---

# Entry 1
**Day, Time, and Location:** February 6th, ~4:01pm EST, Montreal

**How long did the search take?** ~10 seconds

**Photo showing setting of the search:** No photo, but was sitting at a desk with a couple of friends! Casual co-working time.

**Motivation for the search**: A group of us were chatting and one of my friends mentioned her undergraduate thesis on the concept of vibes as applied to fundamental essences of objects. I was curious if she had heard of the term 'qualia' before as the concepts seemed related. I keep a personal online archive of notes on my website and wanted to surface a relevant link that I read but couldn't remember off of the top of my head. Specifically, looking for this article from [Real Life Mag](https://reallifemag.com/nameless-feeling/?curius=1294).

**Details of the search**: Search term: *qualia*, result was in the first three surfaced

**Device type and Search Engine**: Mobile, site-specific search on my personal site (jzhao.xyz)

**Was the search successful?** Finished within one session! Found the note I was looking for with the first query.

**Reflection on the search:** This is a pretty good representation of the average use-case for searching through my own website. If done well, I have a **shareable representation of my thoughts** that I can send out into the world and access easily from any device anywhere.

Search is a pretty default entry point for me into my 'second-brain' (more on why in my post on [networked thought](posts/networked-thought.md)). I use search as an entry-point into a single node, then recall by associativity rather than by indexing. But having a good entry-point can make or break my flow into finding what I’m looking for. In this case, I had already known that this note existed in my garden so I just searched by the title of the note.

Because this search system is still rather brittle, I've learned to start splitting notes into atomic concepts with short, simple nouns like "[qualia](thoughts/qualia.md)" and "[Chesterton's Fence](thoughts/Chesterton's%20Fence.md)" rather than long winding descriptions, which helps me find and organize notes more easily. The engine operates on an extended version of the bag of words model and as such, I have adapted to mostly searching off of keywords rather than more "natural language".

# Entry 2
**Day, Time, and Location:** February 5th, 10:23pm EST, Montreal

**How long did the search take?** ~30 minutes

**Photo showing setting of the search:** No photo. Sitting at desk with a laptop, slightly groggy.

**Motivation for the search**: I am currently working on a digital version of an essay that a collective of technologists I'm a part of is publishing soon. We are doing last minute polish around performance for lower-end devices that may not be able to handle a lot of the more performance-intensive graphics we have. 

**Details of the search**: A collection of searches with queries like "three js gradient skybox", "ScissorCanvas effectcomposer", and a huge string of other searches. Most results led me to issues on GitHub like https://github.com/mrdoob/three.js/issues/6022 and https://github.com/mrdoob/three.js/issues/5979.

**Device type and Search Engine**: Laptop, Google + GitHub code search.

**Was the search successful?** None of the search results were able to give me an exact answer but helped provide context into the history of the issue. For example, the second search result let me know that shaderpasses will use the wrong viewport/scissor for rendering if used in conjunction. I ended up using a slightly hacky workaround to achieve the same effect.

**Reflection on the search:** I have had a decent amount of experience making technical searches in the past. A lot of programming *is* just knowing what combination of search terms will make Google spit out the most relevant search results. Most times, Google surfaces relevant and helpful pages and this was no exception. 

I tend to use search engines like Google very frequently. As a fast typer, my approach is to just stream words that surface from my head and iteratively refine and re-type queries as I visit and park pages (in the terminology of [information foraging](thoughts/information%20foraging.md), I rely heavily on behaviour enrichments and have a tight goal, forage, refine loop).

# Entry 3
**Day, Time, and Location:** February 4th, 2:56pm PST, Vancouver

**How long did the search take?** ~5 minutes

**Photo showing setting of the search:** No photo. At desk while on a Discord call with cool folks!

**Motivation for the search**: We were trying to find a fitting banner image for our community Discord we were setting up! I had remembered seeing a very nice solarpunk-themed video commercial on YouTube somewhere but couldn't quite remember the right combination of search times to find it. I *did* remember that it was somehow a yoghurt commercial.

**Details of the search**: Initial search was for "yoghurt commercial". After immediately realizing this was not specific enough, I asked in the Discord call if people remember the name of the company and then modified it to "Chobani commercial solarpunk" and finally "Chobani commercial solarpunk but no product placement" to remove all the product placement.

**Was the search successful?** Eventually found the "Dear Alice" video that I was looking for! [Video here](https://www.youtube.com/watch?v=UqJJktxCY9U)

**Reflection on the search**: This was a really interesting example of search in a more 'collaborative' fashion. A lot of my information recall happens via association and the more people to help fill in gaps in memory, the faster I am able to find the thing I am looking for. This search in particular took two 'hops' of refinement.

# Entry 4
**Day, Time, and Location:** January 28th, 2:58pm PST, Vancouver

**How long did the search take?** ~1 minute

**Photo showing setting of the search:** No photo. At desk, messaging people on Facebook while eating a meal.

**Motivation for the search**: One of my close friends has been experimenting with the concept of telescopic text (an example: https://www.telescopictext.org/text/KPx0nlXlKTciC). There was a really interesting interaction design experiment that one of my mutual friends on Twitter has been experimenting with that I wanted to share (this one in particular: https://twitter.com/azlenelza/status/1487153246531579905)

**Details of the search**: I had remembered that I bookmarked this tweet reply at some point so the first place I looked was my Bookmarks tab in Twitter. Twitter's search is notoriously bad so I just scrolled chronologically and used cmd+f liberally until I found the tweet.

**Was the search successful?** Yes! I found what I was looking for relatively quickly. It also 'mentally' refreshed a few ideas I had forgotten I had bookmarked like this really cool scoping interaction (https://twitter.com/wcrichton/status/1487223891751694339).

**Reflection on the search**: I think this interaction is really interesting because it is often representative of behaviour on sites where the search system is either non-existent or poorly designed. In these cases, I rely heavily on interaction enrichments like using in-browser search and F-scanning (more on F-scanning: https://www.nngroup.com/articles/f-shaped-pattern-reading-web-content/) of the tweet profile pictures to quickly comb through content. Of course, if this was much further back in time than a few weeks, this would have been a monumentally more difficult search to make.