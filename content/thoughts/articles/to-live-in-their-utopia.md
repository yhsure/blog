---
title: "to-live-in-their-utopia"
date: 2021-06-23T17:13:11-04:00
---

https://ali-alkhatib.com/papers/chi/utopia/utopia.pdf
https://www.youtube.com/watch?v=ClGIosevT0Y

These systems become more actively dangerous when they go from "making sense of the world" to "making the world make sense"

The rules machine learning systems infer from the data have no underlying meaning or reason behind them.
They're just patterns, without any insight into *why* Black people are in prison at much higher rates than white people (for instance).

There's no dataset in the world that adequately conveys white supremacy, or slavery, or colonialism.
So at best these systems generate a facsimile of a world with the shadows of history cast on the ground
skewed, flattened, and always lacking depth that only living these experiences can bring.

Why monopolies (over data and power) are bad
Bureaucracies with no power self-correct (or be corrected) -> they have no place in a world where people can freely walk away or reject the bureaucracy's nonsense

But when the institution *does* wield power and people can't just leave anymore, these institutions can (and do) get more and more detached from the lives and needs of people
Those bureaucracies construct their own worlds where everything gets "rationalized" in simplified, reductive language.

For those of us who can just *not* deal with race, or gender, or sexuality, we get to pass through these systems relatively unscathed. But for those of us who can't ignore those dimensions of who we are, those aspects of ourselves make us stick out.

people talk about "debiasing" data and reviewing code before a model is trained and deployed.
What I'm saying is that even if you've done everything right, if you don't pay attention to the power dynamics as they unfold and play out, the system out in the world is going to drift further and further away from reality.
