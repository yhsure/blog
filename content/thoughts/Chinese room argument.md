---
title: "Searle's Chinese room argument"
date: 2021-12-25
tags:
- seed
---

[Source: Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/chinese-room/)

Mainly a refutation against the Turing test as a means for measuring intelligence. The narrow conclusion of the argument is that programming a digital computer may make it appear to understand language but could not produce real understanding.

"Searle imagines himself alone in a room following a computer program for responding to Chinese characters slipped under the door. Searle understands nothing of Chinese, and yet, by following the program for manipulating symbols and numerals just as a computer does, he sends appropriate strings of Chinese characters back out under the door, and this leads those outside to mistakenly suppose there is a Chinese speaker in the room."

We often attribute "understanding" and other cognitive predicates by metaphor and analogy to things that can't be intentioned like cars and adding machines â€” we make these attributions as we extend our own intentionality onto them (derived intentionality)
-   replies
    1.  systems reply
        -   the symbol manipulator is merely a part of a whole system and the system does understand the story
        -   understanding is not being ascribed to the mere individual, rather it is being ascribed to this whole system of which he is a part
        -   response
            -   individual incorporates the entire system, nullifies the argument
        -   exposing the fault of the turing tests:
            -   two "systems" both of which pass the Turing test, but only one of which understands
    2.  robot reply
        -   put a computer inside a robot, this computer would just operate the robot in such a way that the robot does something very much like perceiving, walking, moving about, hammering nails, eating, etc.
        -   embedded ai argument
        -   response
            -   i know none of these other facts. i am receiving information from the robots perceptual apparatus and I am giving out instructions to its motor apparatus without knowing either of these facts
    3.  brain simulator reply
        -   the machine takes in Chinese stories and questions about them as input, it simulates the formal structure of actual Chinese brains in processing these stories, and it gives out Chinese answers as outputs
        -   what this is saying
            -   strong ai assumption: the mind is to the brain as the program is to the hardware, thus we can understand the mind without doing neurophysiology
            -   if we actually knew how the brain worked, we wouldn't bother with neurophysiology
        -   response
            -   water valves as synapse connections
                -   where is the understanding in this system? operator certainly doesn't understand Chinese and neither do the pipes
                -   absurd to think that the operator in conjunction with the pipes understands it (operator can internalize the pipes)
    4.  combination reply
        -   imagine a robot with a brain-shaped computer lodged in its cranial cavity, computer programmed with all the synapses of the human brain, whole behaviour of the robot is indistinguishable from human behaviour, and now think of the whole thing as a unified system and not just a computer with inputs and outputs
        -   as long as you knew nothing about it, it would be rational to ascribe [intentionality](thoughts/intentionality.md) to the robot
        -   response: doesn't help the claims of strong AI
            -   the attributions of intentionality that we make to the robot in this example have nothing to do with formal programs
            -   if the robot looks and behaves sufficiently like us, then we would suppose until proven otherwise, that is must have mental states like ours that cause and are expressed by its behaviour and it must have an inner mechanism capable of producing such mental states
            -   however, as soon as we knew that the behaviour was the result of a formal program, and that the actual [[thoughts/causality|causal]] properties of the physical substance were irrelevant, we would abandon the assumption of intentionality
    5.  The many mansion reply
    -   will eventually build devices that have these [[thoughts/causality|causal]] processes and that will be artificial intelligence
    -   avoids the original thesis: mental processes are computational processes over formally defined elements
    -   say we gave a machine the capacity to understand English or Chinese
        -   this is possible as our bodies with our brains are precisely such machines
    -   no purely formal model will ever be sufficient by itself for intentionality