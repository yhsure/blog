---
title: "Bias"
date: 2021-10-30
---

More detailed post on [Bias in AI](posts/bias-bug.md). Related readings: [Design Justice](thoughts/Design%20Justice.md), [To Live in their Utopia](thoughts/To%20Live%20in%20their%20Utopia.md)

## Social Bias in Information Retrieval
Source: Addressing Social Bias in Information Retrieval in *In Experimental IR Meets Multilinguality, Multimodality, and Interaction*

"Many algorithmic processes are opaque and that the reasons for this may vary. For instance, it is more often than not difficult to interpret results from models induced by new machine learning techniques such as deep learning" (especially why we need to work on [explainability](thoughts/explainability.md))

As a counter argument, there are social and economic challenges for achieving algorithmic [transparency](thoughts/transparency.md), such as the need for developers/owners of such processes to protect trade secrets, or even the privacy concerns of users.

Friedman and Nissenbaum's definition of bias:
1. its results are slanted in unfair discrimination against particular persons or groups
2. the observed discrimination is systematic within the system

> Indeed, over the past years, many researchers have found that search engines, through the result sets they present to users, tend to reinforce a view of the social world that aligns with the status quo.

Related: [To Live in their Utopia](thoughts/To%20Live%20in%20their%20Utopia.md), [Data Distributions](thoughts/data%20distributions.md), [Algorithms of Oppression](thoughts/Algorithms%20of%20Oppression.md)

## Captchas
How do you distinguish between human and non-human without discriminating against certain types of people (e.g. ethnicity, cultural background)? How does one prove their humanity without betraying anything else about them?

"What is the universal human quality that can be demonstrated to a machine, but that no machine can mimic? What is it to be human?"

> "You need something that’s easy for an average human, it shouldn’t be bound to a specific subgroup of people, and it should be hard for computers at the same time. That’s very limiting in what you can actually do. And it has to be something that a human can do fast, and isn’t too annoying."

Possibility of reverse CAPTCHAs where you can only pass if you get it wrong in the 'right' way? (e.g. optical illusions)

## Ethical Matrices
Who cares about my algorithm? Who are the stakeholders? Why do they care? What are their goals?