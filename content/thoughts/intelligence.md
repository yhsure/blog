---
title: "Can Machines Think?"
date: 2021-07-02T13:29:33-04:00
tags: ["cognitive-sciences"]
---

# Dretske
## Can intelligence be artificial?
-   two ways of thinking about it
	-   like money → everyone has, some have more than others
		-   philosophers view
	-   like wealth → something possessed by only those who have more than the average amount of money
		-   computer scientists view
-   thought alone is not enough, the thoughts need to do something, and sometimes explain the doing
	-   actions that are not governed by/explained by thought are not intelligent
-   in order to be intelligent, the behaviour must be under the control of the content of the thought and not the vehicle of the content
-   plant analogy
	-   even if you know what physical events inside the plant are causing the change in colour, don't necessarily know why the plant is changing colour
		-   could be a result to encouraging different polinators
		-   or discouraging beetles from eating it
		-   what about laboratory grown? has no reason to change colour other than by design
-   to create an intelligence
	-   it not only needs to behave the same way as an intelligent system, but also for reasons
	-   this requires a history in which such governance is made possible

# Searle
## Biological naturalism
Two main theses:
1.  all mental phenomena from pains, tickles, and itches to the most abstruse thoughts are caused by lower-level neurobiological processes in the brain
2.  mental phenomena themselves are higher-level features of the brain

Entails that the brain has the right causal powers to produce intentionality   
-   weak AI → principle value of the computer in the study of the mind is that it gives us a very powerful tool
-   strong AI → the appropriately programmed computer really IS a mind    
    -   computers, given the right programs, can be literally said to understand and have other cognitive states
-   attempting to refute the claims that
    1.  the machine can literally be said to understand the story and provide the answers to questions
    2.  what the machine and its programs do explains the human ability to understand the story and answer questions about it

## Chinese room argument
-   given 3 batches of text
	-   script
	-   story
	-   questions
-   symbols returned
	-   questions → answers to the question
-   english rules given
	-   the program
-   from an external point of view, symbols returned are indistinguishable from those of a native Chinese speaker
	-   however in the chinese case, you produce the answers by manipulating uninterpreted formal symbols
-   as it applies to the two claims
	1.  the symbol manipulator clearly does not understand a word of chinese
	2.  whatever purely format principles are inserted into the computer, they won't be sufficient for understanding as a human will be able to follow the formal principles without understanding anything!
-   often attribute "understanding" and other cognitive predicates by metaphor and analogy to things that can't be intentioned like cars and adding machines — we make these attributions as we extend our own intentionality onto them (derived intentionality)
-   replies
    1.  systems reply
        -   the symbol manipulator is merely a part of a whole system and the system does understand the story
        -   understanding is not being ascribed to the mere individual, rather it is being ascribed to this whole system of which he is a part
        -   response
            -   individual incorporates the entire system, nullifies the argument
        -   exposing the fault of the turing tests:
            -   two "systems" both of which pass the Turing test, but only one of which understands
    2.  robot reply
        -   put a computer inside a robot, this computer would just operate the robot in such a way that the robot does something very much like perceiving, walking, moving about, hammering nails, eating, etc.
        -   embedded ai argument
        -   response
            -   i know none of these other facts. i am receiving information from the robots perceptual apparatus and I am giving out instructions to its motor apparatus without knowing either of these facts
    3.  brain simulator reply
        -   the machine takes in Chinese stories and questions about them as input, it simulates the formal structure of actual Chinese brains in processing these stories, and it gives out Chinese answers as outputs
        -   what this is saying
            -   strong ai assumption: the mind is to the brain as the program is to the hardware, thus we can understand the mind without doing neurophysiology
            -   if we actually knew how the brain worked, we wouldn't bother with neurophysiology
        -   response
            -   water valves as synapse connections
                -   where is the understanding in this system? operator certainly doesn't understand Chinese and neither do the pipes
                -   absurd to think that the operator in conjunction with the pipes understands it (operator can internalize the pipes)
    4.  combination reply
        -   imagine a robot with a brain-shaped computer lodged in its cranial cavity, computer programmed with all the synapses of the human brain, whole behaviour of the robot is indistinguishable from human behaviour, and now think of the whole thing as a unified system and not just a computer with inputs and outputs
        -   as long as you knew nothing about it, it would be rational to ascribe intentionality to the robot
        -   response: doesn't help the claims of strong AI
            -   the attributions of intentionality that we make to the robot in this example have nothing to do with formal programs
            -   if the robot looks and behaves sufficiently like us, then we would suppose until proven otherwise, that is must have mental states like ours that cause and are expressed by its behaviour and it must have an inner mechanism capable of producing such mental states
            -   however, as soon as we knew that the behaviour was the result of a formal program, and that the actual causal properties of the physical substance were irrelevant, we would abandon the assumption of intentionality
    5.  The many mansion reply
    -   will eventually build devices that have these causal processes and that will be artificial intelligence
    -   avoids the original thesis: mental processes are computational processes over formally defined elements
    -   say we gave a machine the capacity to understand English or Chinese
        -   this is possible as our bodies with our brains are precisely such machines
    -   no purely formal model will ever be sufficient by itself for intentionality

## Clarifications
-   can a machine think → yes
	-   we are precisely such machines
	-   only machines can think
	-   only very special kinds of machines (namely things with the causal powers as brains)
	-   why strong AI has little to tell us about thinking → its about programs and programs are not machines
-   could an artifact, a man-made machine, think? → yes
	-   if we can produce artificially a machine with a nervous system, neurons with axons and dendrites, and all the rest of it, the answer is yes.
	-   if you can duplicate the causes, you could duplicate the effects
-   can a digital computer think → yes
	-   "digital computer" as something that can be describes as the instantiation of a computer program
	-   since we are the instantiations of any number of computer programs, we can think
-   can something think, understand, and so on SOLELY based on the virtue of being a computer with a specific program? no
	-   formal symbol manipulations by themselves dont have intentionality → only syntax, no semantics
	-   intentionality is derived
	-   chinese room example tries to show that even programming something with intentionality (a person) with a format program, that formal program carries no additional intentionality

## Information Processing
-   argument that rests on the ambiguity of what "information" is
-   construing information processing that implies intentionality
	-   programmed computer does not do information processes, it only manipulates formal symbols
-   doesn't imply intentionality
	-   information transformation → taking info at one end, transforming it, and producing different information as output
	-   up to outside observers to interpret the input and output as information the ordinary sense
-   strong AI only makes sense given the dualistic assumptions that, where the mind is concerned, the brain doesn't matter

# Crane
-   mind as a computer
    -   like a computer, a causal mechanism which in some sense 'contains' representations
-   two questions
    -   can a computer think? can anything think by simply being a computer
        -   this chapter
    -   is the human mind a computer? more precisely, are any actual mental states and processes computational
## What is a computer?
- device which processes [representations](/thoughts/representation) in a systematic way
-   algorithm → method for calculating the value of a function
	-   "effective procedures" → procedures which, if applied correctly, are entirely effective in bringing about their results (always work)
	-   computable if the algorithm gives the value of a function for any argument
	-   church's thesis → anything that can be executed by a turing machine
-   conditions to be considered an algorithm
	-   definite next step
	-   finite number of steps
## Turing machine
- the simplest possible device that could perform any computation no matter how complicated
    -   has long (infinitely long) tape with squares
    -   device that can write/read the symbols on the tape
    -   device can have and change internal states
    -   device can move tap one left or one right
    -   possible operations are dictated by machine's 'machine table'
        -   a set of instructions of the form 'if the machine is in state X and reading symbol S, then do Y and move tape right/left'
    -   makes the idea of an effective procedure unmysterious
    -   -   functions
    -   an interaction instantiates a function if the interaction is an instance of that function
        -   e.g. kepler's law, they describe the solar system but they don't _compute_ the solar system
## Instantiating vs Computing function
-   instantiating → being an instance of/describable by a function
-   computing → employs representations of input and output
-   even if a person could be modeled by a Turing machine, that would not show that thinkers are computers, rather, it would show that a thinker instantiates a function, not that it computes that function.
-   much to difficult to calculate everything in real-time, employ the use of heuristics to help us make best judgements (e.g. Ten Commandments)
-   functional analysis → analysis of the working of the machine into the functions of its component parts
## Cognition, computation, and functionalism
-   mechanical view of the mind → mind is a part of nature, which has a regular, law-governed causal structure
-   different view → causal structure of the mind is also a computational structure - that thinking is computing
-   'reckoning' → calculation
-   computational mental states
	-   computation is defined in terms of representation
	-   representationalism / intentionalism → all mental states in all their aspects, are representational in nature
	-   beliefs are the best candidate
-   computational theory of cognition → representational states are related to one another in a computational way